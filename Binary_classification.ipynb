{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6343fe45",
   "metadata": {
    "id": "6343fe45"
   },
   "source": [
    "# Импорт библиотек и обучающих данных:\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871265ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "871265ff",
    "outputId": "8a581d14-5d3c-4840-956e-c7f8607080f5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import copy\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2fc707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75623c10",
   "metadata": {},
   "source": [
    "# Разархивация изображений\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efb317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(r\"data\\welds.zip\",'r') as zip_obj:\n",
    "#         zip_obj.extractall(r\"data\\binary_root\")\n",
    "# data_root = r\"data\\binary_root\"\n",
    "# print('Файлы выгрузились из архива успешно!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ziECZmMoUhw",
   "metadata": {
    "id": "7ziECZmMoUhw"
   },
   "source": [
    "# Разметка данных:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2OuvzFBYoULY",
   "metadata": {
    "id": "2OuvzFBYoULY"
   },
   "source": [
    "У меня есть json файл с разметкой. Надо его пропарсить. Добавляю столбец для класса в бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rGY-69T2oVd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rGY-69T2oVd4",
    "outputId": "ce857277-d322-4865-f616-f0ecbc221d85"
   },
   "outputs": [],
   "source": [
    "# js = os.path.join(data_root, r\"al5083\\train\\train.json\")\n",
    "# labels = pd.read_json(js, typ='series')\n",
    "# labels = labels.to_frame().reset_index().rename(columns={'index':'path',0:'class'})\n",
    "# def create_binary_label(row):\n",
    "#     if row['class'] == 0:\n",
    "#         return 'good_weld'\n",
    "#     else:\n",
    "#         return 'bad_weld'\n",
    "# labels['binary'] = labels.apply(create_binary_label, axis=1)\n",
    "# labels = labels.sort_values(by='binary').reset_index().drop(['index','class'],axis=1)\n",
    "# classes = labels['binary'].unique()\n",
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa8974",
   "metadata": {},
   "source": [
    "Для повышения точности модели решено создать две нейросети - первая будет бинарно классифицировать хорошие и плохие швы, а вторая будет определять вид дефекта у плохих швов. Для балансировки данных в бинарной классификации необходимо удвоить количество хороших швов за счёт аугментации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e0808",
   "metadata": {
    "id": "241e0808"
   },
   "source": [
    "# Разбивка данных на обучающие и валидационные:\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0b02f",
   "metadata": {
    "id": "fab0b02f"
   },
   "source": [
    "Собираю вместе все good и bad weld's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36908de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = classes\n",
    "# train_data = os.path.join(data_root, r'al5083\\train')\n",
    "# for class_name in class_names: \n",
    "#     for i, file_name in enumerate(tqdm(labels['path'].loc[labels['binary']==class_name].tolist())):\n",
    "#         pic_name = str(class_name) + '_' + str(i) + '.png'\n",
    "#         shutil.copy(os.path.join(train_data, file_name), os.path.join(os.path.join(data_root, r\"welds\",class_name, pic_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef8f032",
   "metadata": {},
   "source": [
    "Отзеркаливаю good welds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bca9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# # Путь к директории с изображениями\n",
    "# image_dir = r\"C:\\Users\\HP\\Documents\\Artificial_Intelligence\\Проекты для CV\\weld_inspection\\data\\binary_root\\welds\\good_weld\"\n",
    "\n",
    "# # Получение списка файлов изображений в директории\n",
    "# image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f)) and f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# # Создание зеркальных копий изображений\n",
    "# for file_name in tqdm(image_files):\n",
    "#     file_path = os.path.join(image_dir, file_name)\n",
    "#     image = Image.open(file_path)\n",
    "#     flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "#     flipped_file_name = \"flipped_\" + file_name\n",
    "#     flipped_file_path = os.path.join(image_dir, flipped_file_name)\n",
    "#     flipped_image.save(flipped_file_path)\n",
    "\n",
    "# print(\"Зеркальные копии изображений успешно созданы.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af643",
   "metadata": {},
   "source": [
    "Создаю валидационную и обучающую папки и загружаю в них данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db114cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_dir = os.path.join(data_root,'train')\n",
    "# # val_dir = os.path.join(data_root,'val')\n",
    "# # class_names = classes # некий список классов нашей классификации.\n",
    "\n",
    "# # for dir_name in [train_dir, val_dir]: #итерация через 2 строчки\n",
    "# #     for class_name in class_names: # для каждого имени класса  в списке классов\n",
    "# #         os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
    "# # print('Успешно созданы папки val и train с классами швов!')\n",
    "\n",
    "# train_dir = r\"data\\binary_root\\learning\\train\"\n",
    "# val_dir = r\"data\\binary_root\\learning\\val\"\n",
    "# good_weld_dir = r\"data\\binary_root\\welds\\good_weld\"\n",
    "# bad_weld_dir = r\"data\\binary_root\\welds\\bad_weld\"\n",
    "\n",
    "# classes = ['bad_weld','good_weld']\n",
    "\n",
    "# good_weld_files = [f for f in os.listdir(good_weld_dir) if os.path.isfile(os.path.join(good_weld_dir, f))]\n",
    "# bad_weld_files = [f for f in os.listdir(bad_weld_dir) if os.path.isfile(os.path.join(bad_weld_dir, f))]\n",
    "\n",
    "# # Перемещение изображений в папки train и val\n",
    "\n",
    "# for i, file_name in enumerate(tqdm(good_weld_files)):\n",
    "#     src_path = os.path.join(good_weld_dir, file_name)\n",
    "#     if i % 6 == 0:\n",
    "#         dst_path = os.path.join(val_dir, 'good_weld', file_name)\n",
    "#     else:\n",
    "#         dst_path = os.path.join(train_dir, 'good_weld', file_name)\n",
    "#     shutil.copy(src_path, dst_path)\n",
    "\n",
    "# for i, file_name in enumerate(tqdm(bad_weld_files)):\n",
    "#     src_path = os.path.join(bad_weld_dir, file_name)\n",
    "#     if i % 6 == 0:\n",
    "#         dst_path = os.path.join(val_dir, 'bad_weld', file_name)\n",
    "#     else:\n",
    "#         dst_path = os.path.join(train_dir,'bad_weld', file_name)\n",
    "#     shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k6iMq5x2R48H",
   "metadata": {
    "id": "k6iMq5x2R48H"
   },
   "source": [
    "Проверяем корректность разбивки файлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iQQKO8uYIeiK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQQKO8uYIeiK",
    "outputId": "e3569233-bcc1-4096-8ad0-cee19f9b53be"
   },
   "outputs": [],
   "source": [
    "# lst_train = []\n",
    "# lst_val = []\n",
    "# for type in classes:\n",
    "#     items_train = os.listdir(os.path.join(train_dir,type))\n",
    "#     items_val =  os.listdir(os.path.join(val_dir,type))\n",
    "#     lst_train.append(len(items_train))\n",
    "#     lst_val.append(len(items_val))\n",
    "# print('Всего изображений в деле: ', sum(lst_train) + sum(lst_val))\n",
    "# print('Всего на обучении: ', sum(lst_train))\n",
    "# print('Всего на валидации: ', sum(lst_val))\n",
    "# print('Отношение обучающих данных к валидационным: ', sum(lst_train) / sum(lst_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a12c1b",
   "metadata": {
    "id": "55a12c1b"
   },
   "source": [
    "# Трансформация и аугментация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ab8cd",
   "metadata": {
    "id": "b18ab8cd"
   },
   "source": [
    "В качестве baseline'а применяется архитектура VGG-19. У данной архитектуры есть требования к исходным изображениям:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30c3afd4",
   "metadata": {
    "id": "30c3afd4"
   },
   "source": [
    "Размер - 224 * 224\n",
    "Пространство RGB\n",
    "Нормализация значений\n",
    "Отсутствие искажений\n",
    "Отсутствие шумов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7a812",
   "metadata": {
    "id": "18f7a812"
   },
   "source": [
    "По этой причине трансформация валидационного изображения будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b693fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающих изображений:  29519\n",
      "Валидационных изображений:  5905\n"
     ]
    }
   ],
   "source": [
    "train_dir = r\"data\\binary_root\\learning\\train\"\n",
    "val_dir = r\"data\\binary_root\\learning\\val\"\n",
    "\n",
    "transforms_all = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=transforms_all)\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, transform=transforms_all)\n",
    "print('Обучающих изображений: ', len(train_dataset))\n",
    "print('Валидационных изображений: ', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60948b",
   "metadata": {
    "id": "2c60948b"
   },
   "source": [
    "# Определяю размер batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4877b80",
   "metadata": {
    "id": "b4877b80"
   },
   "source": [
    "При большом числе будет меньше обновлений весов - модель попробует учесть все изображения в одном разе. При малом числе батчей - веса будут обновляться постоянно, но модель будет учитывать малое число изображений. Начнём с 8, буду исследовать для:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee1e06e",
   "metadata": {
    "id": "aee1e06e"
   },
   "outputs": [],
   "source": [
    "batch_size = 2# размер бача, т.е. кол-во пикчей, используемых на 1 эпохе/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af15746",
   "metadata": {
    "id": "1af15746"
   },
   "source": [
    "Применение трансформаций для изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfaceb0",
   "metadata": {
    "id": "cdfaceb0"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff3b59",
   "metadata": {
    "id": "efff3b59"
   },
   "source": [
    "\n",
    "# Определение архитектуры модели:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc4726",
   "metadata": {
    "id": "bfbc4726"
   },
   "source": [
    "Архитектура исследуемой модели представлена ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0bf0874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0bf0874",
    "outputId": "8e56d570-e25d-41c8-81c0-b774de23d2ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\envs\\gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предобученных моделей\n",
    "model = models.vgg11(pretrained=True)\n",
    "#model = models.vgg19(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#model = models.densenet121(pretrained=True) \n",
    "#model = models.resnet18(pretrained=True)\n",
    "#model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Замена последнего полносвязного слоя на новый слой для 6 классов\n",
    "# num_classes = 2\n",
    "# model.classifier._modules['2'] = torch.nn.Linear(4096, num_classes)\n",
    "# Замена последнего полносвязного слоя на новый слой для 6 классов ДЛЯ RESNET\n",
    "# num_classes = 6\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "# Вывод архитектуры модели с новым слоем\n",
    "# Загрузка предобученной модели AlexNet\n",
    "#model = models.alexnet(pretrained=True)\n",
    "# weights= VGG19_Weights.DEFAULT\n",
    "# Замена последнего слоя классификатора\n",
    "num_features = model.classifier[-1].in_features\n",
    "model.classifier[-1] = nn.Linear(num_features, 1)  # Заменяем на один выходной нейрон\n",
    "\n",
    "# Применение функции активации (например, сигмоиды) для бинарной классификации\n",
    "model.classifier.add_module(\"sigmoid\", nn.Sigmoid())\n",
    "# Печать измененной модели\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68166a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d59e12",
   "metadata": {
    "id": "54d59e12"
   },
   "source": [
    "Ниже определяем лосс-функцию. По дефолту это Кросс-энтропия, т.к в примере была именно она"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f493304b",
   "metadata": {
    "id": "f493304b"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss() # функция потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee7e5f",
   "metadata": {
    "id": "88ee7e5f"
   },
   "source": [
    "Learning_rate = 0.001 по дефолту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63821a23",
   "metadata": {
    "id": "63821a23"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270d28b",
   "metadata": {
    "id": "5270d28b"
   },
   "source": [
    "Оптимайзер в начале исследования всегда лучше начинать с СГД:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8028b869",
   "metadata": {
    "id": "8028b869"
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# beta1 = 0.9\n",
    "# beta2 = 0.999\n",
    "# eps = 0.00001\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta1, beta2), eps=eps, amsgrad = True)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Rmspror(model.parameters(), lr=learning_rate)\n",
    "# alpha = 0.01\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e1157",
   "metadata": {},
   "source": [
    "Хочу отметить, что на этом этапе я усвоил урок - параметры оптимизатора - очень важны. Поменяв alpha для RMprop с 0.9 до 0.1 результат изменился в 3,5 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f317b1c",
   "metadata": {
    "id": "8f317b1c"
   },
   "source": [
    "Уменьшение шага градиента сначала поставим 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e53f85",
   "metadata": {
    "id": "70e53f85"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # уменьшение шага градиентного спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832bbda",
   "metadata": {
    "id": "4832bbda"
   },
   "source": [
    "Число эпох 15, посмотрим как долго будет обучаться модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d50cc4c",
   "metadata": {
    "id": "3d50cc4c"
   },
   "outputs": [],
   "source": [
    "num_epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab97c13c",
   "metadata": {
    "id": "ab97c13c"
   },
   "source": [
    "\n",
    "# Обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd455f2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "dd455f2f",
    "outputId": "199dc0a4-36ed-48a8-da47-4fc1d62076ea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14760 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 2.00 GiB total capacity; 1.49 GiB already allocated; 0 bytes free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 14\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Оценка точности на валидационных данных\u001b[39;00m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     68\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\optim\\adagrad.py:123\u001b[0m, in \u001b[0;36mAdagrad.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    119\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    121\u001b[0m     has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(group, params_with_grad, grads, state_sums, state_steps)\n\u001b[1;32m--> 123\u001b[0m     \u001b[43madagrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_sums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\optim\\adagrad.py:223\u001b[0m, in \u001b[0;36madagrad\u001b[1;34m(params, grads, state_sums, state_steps, has_sparse_grad, foreach, differentiable, lr, weight_decay, lr_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adagrad\n\u001b[1;32m--> 223\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_sums\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\torch\\optim\\adagrad.py:360\u001b[0m, in \u001b[0;36m_multi_tensor_adagrad\u001b[1;34m(params, grads, state_sums, state_steps, lr, weight_decay, lr_decay, eps, has_sparse_grad, maximize, differentiable)\u001b[0m\n\u001b[0;32m    356\u001b[0m device_state_sums \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    357\u001b[0m     torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_state_sums\n\u001b[0;32m    358\u001b[0m ]\n\u001b[0;32m    359\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcmul_(device_state_sums, device_grads, device_grads, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_add(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_state_sums\u001b[49m\u001b[43m)\u001b[49m, eps)\n\u001b[0;32m    361\u001b[0m toAdd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_div(torch\u001b[38;5;241m.\u001b[39m_foreach_mul(device_grads, minus_clr), std)\n\u001b[0;32m    362\u001b[0m toAdd \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    363\u001b[0m     torch\u001b[38;5;241m.\u001b[39mview_as_complex(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(device_params[i]) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(toAdd)\n\u001b[0;32m    365\u001b[0m ]\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 2.00 GiB total capacity; 1.49 GiB already allocated; 0 bytes free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "no_improvement_count = 0\n",
    "patience = 2\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Оценка точности на валидационных данных\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for inputs, labels in tqdm(val_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.where(outputs < 0.5, torch.tensor(0.0), torch.tensor(1.0))\n",
    "#             predicted = torch.round(outputs)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze().long() == labels).sum().item()\n",
    "            accuracy = correct / total\n",
    "    \n",
    "    # Проверяем, улучшилась ли точность на этой эпохе\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        no_improvement_count = 0\n",
    "        print('Модель улучшена!')\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        print('Модель не улучшилась, обучение продолжается')\n",
    "    \n",
    "    # Если точность не улучшалась в течение patience эпох, прекращаем обучение\n",
    "    if no_improvement_count == patience:\n",
    "        print('No improvement for {} epochs. Stopping training.'.format(patience))\n",
    "        break\n",
    "    \n",
    "    # Выводим информацию о текущей эпохе\n",
    "    print('Epoch {}/{}:'.format(epoch + 1, num_epochs), flush=True)\n",
    "    print('Training Loss: {:.4f}'.format(loss.item()), flush=True)\n",
    "    print('Validation Accuracy: {:.4f}'.format(accuracy), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26986bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=\"cuda:0\", abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c675d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a48249",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ba326",
   "metadata": {
    "id": "ee9ba326"
   },
   "source": [
    "# Сохранение обученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf33a05",
   "metadata": {
    "id": "bcf33a05"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model, 'vgg13_sgd_binary.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852215f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
