{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6343fe45",
   "metadata": {
    "id": "6343fe45"
   },
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dcbd96",
   "metadata": {},
   "source": [
    "After the first neural network has classified the seam as poor quality, it is necessary to determine the type of defect. I can do this with the help of a second neural network that will do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb85ab",
   "metadata": {},
   "source": [
    "## STEP 1. Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "871265ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "871265ff",
    "outputId": "8a581d14-5d3c-4840-956e-c7f8607080f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import copy\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import torch.nn as nn\n",
    "data_root = r\"data\\data_root\\al5083\\train\"\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ziECZmMoUhw",
   "metadata": {
    "id": "7ziECZmMoUhw"
   },
   "source": [
    "## STEP 2. Data markup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2OuvzFBYoULY",
   "metadata": {
    "id": "2OuvzFBYoULY"
   },
   "source": [
    "I have a json file with markup. I need to parse it. I am adding a column for a multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rGY-69T2oVd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rGY-69T2oVd4",
    "outputId": "ce857277-d322-4865-f616-f0ecbc221d85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170906-113317-Al 2mm-part3/frame_00647.png</td>\n",
       "      <td>burn_through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170906-144958-Al 2mm/frame_01521.png</td>\n",
       "      <td>burn_through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170906-144958-Al 2mm/frame_01128.png</td>\n",
       "      <td>burn_through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170906-144958-Al 2mm/frame_01144.png</td>\n",
       "      <td>burn_through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170906-144958-Al 2mm/frame_01239.png</td>\n",
       "      <td>burn_through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>170904-113012-Al 2mm-part2/frame_00829.png</td>\n",
       "      <td>misalignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26662</th>\n",
       "      <td>170904-113012-Al 2mm-part2/frame_00686.png</td>\n",
       "      <td>misalignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26663</th>\n",
       "      <td>170904-113012-Al 2mm-part2/frame_00550.png</td>\n",
       "      <td>misalignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26664</th>\n",
       "      <td>170904-113012-Al 2mm-part2/frame_00660.png</td>\n",
       "      <td>misalignment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26665</th>\n",
       "      <td>170904-145718-Al 2mm-part2/frame_00645.png</td>\n",
       "      <td>misalignment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17908 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             path         class\n",
       "0      170906-113317-Al 2mm-part3/frame_00647.png  burn_through\n",
       "1            170906-144958-Al 2mm/frame_01521.png  burn_through\n",
       "2            170906-144958-Al 2mm/frame_01128.png  burn_through\n",
       "3            170906-144958-Al 2mm/frame_01144.png  burn_through\n",
       "4            170906-144958-Al 2mm/frame_01239.png  burn_through\n",
       "...                                           ...           ...\n",
       "26661  170904-113012-Al 2mm-part2/frame_00829.png  misalignment\n",
       "26662  170904-113012-Al 2mm-part2/frame_00686.png  misalignment\n",
       "26663  170904-113012-Al 2mm-part2/frame_00550.png  misalignment\n",
       "26664  170904-113012-Al 2mm-part2/frame_00660.png  misalignment\n",
       "26665  170904-145718-Al 2mm-part2/frame_00645.png  misalignment\n",
       "\n",
       "[17908 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js = os.path.join(data_root, r\"train.json\")\n",
    "labels = pd.read_json(js, typ='series')\n",
    "labels = labels.to_frame().reset_index().rename(columns={'index':'path',0:'class'})\n",
    "labels['class'] = labels['class'].replace({0:'good_weld',\n",
    "                                           1:'burn_through',\n",
    "                                           2:'contamination',\n",
    "                                           3:'lack_of_fusion',\n",
    "                                           4:'misalignment',\n",
    "                                           5:'lack_of_penetration'})\n",
    "labels = labels.sort_values(by='class').reset_index().drop('index',axis=1)\n",
    "labels = labels.loc[labels['class'] != 'good_weld']\n",
    "classes = labels['class'].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e0808",
   "metadata": {
    "id": "241e0808"
   },
   "source": [
    "## STEP 3. Split the data into training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0b02f",
   "metadata": {
    "id": "fab0b02f"
   },
   "source": [
    "As in binary categorization, I decided to split the data 5 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0eae800",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0eae800",
    "outputId": "abb93bdd-2468-4172-caaa-31295f478aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "many_classes_root = r\"data\\multiclass_train\"\n",
    "train_dir = os.path.join(many_classes_root,'train')\n",
    "val_dir = os.path.join(many_classes_root,'val')\n",
    "for dir_name in [train_dir, val_dir]: #итерация через 2 строчки\n",
    "    for class_name in classes: # для каждого имени класса  в списке классов\n",
    "        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s_v8663ICaeB",
   "metadata": {
    "id": "s_v8663ICaeB"
   },
   "source": [
    "I'd like to point out a problem I've encountered - when copying files to a shared directory, files with the same name replace each other.... You have to rename them somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ufoXXoF3OfC8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufoXXoF3OfC8",
    "outputId": "9a7db63c-a428-4643-b8b1-7c0a5e025b39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1783/1783 [00:08<00:00, 204.76it/s]\n",
      "100%|██████████| 6325/6325 [00:32<00:00, 191.92it/s]\n",
      "100%|██████████| 4028/4028 [00:21<00:00, 188.42it/s]\n",
      "100%|██████████| 2819/2819 [00:14<00:00, 196.06it/s]\n",
      "100%|██████████| 2953/2953 [00:13<00:00, 213.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изображения отсортированы по train и val!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes: \n",
    "    for i, file_name in enumerate(tqdm(labels['path'].loc[labels['class']==class_name].tolist())):\n",
    "        pic_name = str(class_name) + \"_\" + str(i) + '.jpg'\n",
    "        if i % 6 != 0:\n",
    "            shutil.copy(os.path.join(data_root, file_name), os.path.join(os.path.join(train_dir, class_name, pic_name)))\n",
    "        else:\n",
    "            shutil.copy(os.path.join(data_root, file_name), os.path.join(os.path.join(val_dir, class_name, pic_name)))\n",
    "print('Изображения отсортированы по train и val!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k6iMq5x2R48H",
   "metadata": {
    "id": "k6iMq5x2R48H"
   },
   "source": [
    "Check the correctness of file partitioning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "iQQKO8uYIeiK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQQKO8uYIeiK",
    "outputId": "e3569233-bcc1-4096-8ad0-cee19f9b53be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего изображений в деле:  17908\n",
      "Всего на обучении:  14920\n",
      "Всего на валидации:  2988\n",
      "Отношение обучающих данных к валидационным:  4.99330655957162\n",
      "burn_through 1485\n",
      "contamination 5270\n",
      "lack_of_fusion 3356\n",
      "lack_of_penetration 2349\n",
      "misalignment 2460\n"
     ]
    }
   ],
   "source": [
    "lst_train = []\n",
    "lst_val = []\n",
    "for type in classes:\n",
    "    items_train = os.listdir(os.path.join(train_dir,type))\n",
    "    items_val =  os.listdir(os.path.join(val_dir,type))\n",
    "    lst_train.append(len(items_train))\n",
    "    lst_val.append(len(items_val))\n",
    "print('Всего изображений в деле: ', sum(lst_train) + sum(lst_val))\n",
    "print('Всего на обучении: ', sum(lst_train))\n",
    "print('Всего на валидации: ', sum(lst_val))\n",
    "print('Отношение обучающих данных к валидационным: ', sum(lst_train) / sum(lst_val))\n",
    "for cls in classes:\n",
    "    print(cls, len(os.listdir(os.path.join(many_classes_root,'train',cls))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a12c1b",
   "metadata": {
    "id": "55a12c1b"
   },
   "source": [
    "## STEP 4. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ab8cd",
   "metadata": {
    "id": "b18ab8cd"
   },
   "source": [
    "Here everything is similar to the binary classification. However, now for data balancing I decided to use weighted loss in defining the loss function. This is another method for data balancing and it is better suited for cases when there are many classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "233efa06",
   "metadata": {
    "id": "233efa06"
   },
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd04847",
   "metadata": {
    "id": "7fd04847"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "])\n",
    "train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a1b2d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10a1b2d1",
    "outputId": "094df347-9b39-4945-a537-b2c314cceac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающих изображений:  14920\n",
      "Валидационных изображений:  2988\n"
     ]
    }
   ],
   "source": [
    "print('Обучающих изображений: ', len(train_dataset))\n",
    "print('Валидационных изображений: ', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4fd7d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.99330655957162"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset) / len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60948b",
   "metadata": {
    "id": "2c60948b"
   },
   "source": [
    "## STEP 5.  Define the architecture of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4877b80",
   "metadata": {
    "id": "b4877b80"
   },
   "source": [
    "Based on the results of the study, it became clear that the optimal model for this task is VGG11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67ad3ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True) \n",
    "num_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_features, 1)\n",
    "model.classifier.add_module(\"sigmoid\", nn.Sigmoid())\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fbd6e2",
   "metadata": {},
   "source": [
    "## STEP 6. Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86dcc520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "class_weights = torch.tensor([1485, 5270, 3356, 2349, 2460], dtype=torch.float)\n",
    "class_weights = 1 / class_weights \n",
    "class_weights = class_weights / torch.sum(class_weights)  \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "num_epochs=50\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce85bd",
   "metadata": {},
   "source": [
    "Now I can load the data into the dataloader, set the batch_size and shuffle at each new step and start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdfaceb0",
   "metadata": {
    "id": "cdfaceb0"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=2) \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff3b59",
   "metadata": {
    "id": "efff3b59"
   },
   "source": [
    "## STEP 7. Fit the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d59e12",
   "metadata": {
    "id": "54d59e12"
   },
   "source": [
    "I will assume that if the accuracy of the model has stopped improving over 5 epochs, then the accuracy can no longer increase significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd455f2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "dd455f2f",
    "outputId": "199dc0a4-36ed-48a8-da47-4fc1d62076ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes!\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "no_improvement_count = 0\n",
    "patience = 5\n",
    "for epoch in range(50):\n",
    "    # Обучение на тренировочных данных\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Оценка точности на валидационных данных\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for inputs, labels in tqdm(val_dataloader):\n",
    "          inputs = inputs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = model(inputs).to(device)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "    \n",
    "    # Проверяем, улучшилась ли точность на этой эпохе\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        no_improvement_count = 0\n",
    "        print('Модель улучшена!')\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "        print('Модель не улучшилась, обучение продолжается')\n",
    "    \n",
    "    # Если точность не улучшалась в течение patience эпох, прекращаем обучение\n",
    "    if no_improvement_count == patience:\n",
    "        print('No improvement for {} epochs. Stopping training.'.format(patience))\n",
    "        break\n",
    "    \n",
    "    # Выводим информацию о текущей эпохе\n",
    "    print('Epoch {}/{}:'.format(epoch + 1, num_epochs), flush=True)\n",
    "    print('Training Loss: {:.4f}'.format(loss.item()), flush=True)\n",
    "    print('Validation Accuracy: {:.4f}'.format(accuracy), flush=True)\n",
    "print('Succes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ba326",
   "metadata": {
    "id": "ee9ba326"
   },
   "source": [
    "## STEP 8. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcf33a05",
   "metadata": {
    "id": "bcf33a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes!\n"
     ]
    }
   ],
   "source": [
    "# torch.save(best_model, 'desnet169_adagrad_5classes.pth')\n",
    "print('Succes!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
